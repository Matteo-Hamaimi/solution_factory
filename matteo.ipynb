{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Id   ProductId          UserId               ProfileName  \\\n",
      "508  509  B000G6RYNE  A3I5AT1101AS3A           Nikolette Tripp   \n",
      "509  510  B000G6RYNE  A22LENLDTGQIU7                R. Yamaoka   \n",
      "516  517  B000G6RYNE  A38KP1POQ191WT  Judy Schinske \"Veronica\"   \n",
      "528  529  B000G6RYNE  A1BXG0K7UD9CTD         MicTrik \"mictrik\"   \n",
      "537  538  B000G6RYNE  A18VDAH788BOAC                      Geeb   \n",
      "\n",
      "     HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
      "508                     1                       2      1  1233360000   \n",
      "509                     4                       7      1  1252713600   \n",
      "516                     0                       1      1  1279065600   \n",
      "528                    20                      27      1  1254009600   \n",
      "537                     1                       3      1  1331856000   \n",
      "\n",
      "                                            Summary  \\\n",
      "508                     Maybe the worst chips ever.   \n",
      "509                   Surprise 1  It's different...   \n",
      "516       I have had better \"Jalapeno Kettle Chips\"   \n",
      "528  They changed the Chips now they taste horrible   \n",
      "537                                  Gone down hill   \n",
      "\n",
      "                                                  Text  \n",
      "508  These are perhaps the worst chips that have ev...  \n",
      "509  Kettle chips now look, feel and taste like Lay...  \n",
      "516  These were nasty, they were so greasy and too ...  \n",
      "528  I once loved these chips and they were the onl...  \n",
      "537  When originally produced in England  these we'...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.metrics import accuracy_score\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from pprint import pprint\n",
    "import gensim.corpora as corpora\n",
    "\n",
    "\n",
    "\n",
    "# Charger le dataset\n",
    "df = pd.read_csv('data.csv',nrows=10000)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Filtrer les données pour le produit spécifique et les scores 1 et 5\n",
    "data = df.loc[(df['ProductId'] == 'B000G6RYNE') & (df['Score'] == 1)]\n",
    "\n",
    "print(data.head())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jh/lt1l6hb94_b8vqvq3m3ld1lm0000gn/T/ipykernel_1008/2821783067.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data.drop(['Id', 'ProductId','UserId', 'ProfileName', 'HelpfulnessNumerator', 'HelpfulnessDenominator', 'Time',], axis=1, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "508    perhaps worst chip ever gone mouthfor entire l...\n",
      "509    kettle chip look feel taste like lay chip used...\n",
      "516    nasty greasy rich blood plus lacked major flav...\n",
      "528    loved chip chip would buy discovered england b...\n",
      "537    originally produced england best chip ever tas...\n",
      "538    opening numerous bag found none chip flavoring...\n",
      "541    ive bought local supermarket enjoyed although ...\n",
      "543    kettle brand chip used goodoily crunchy flavor...\n",
      "544    absolutely forget confirmed reviewer chip tota...\n",
      "545    chip nasty thought someone spilled drink bag c...\n",
      "547    bought brand trial since tired pingosit claim ...\n",
      "550    ordered kettle chip following flavvorssalt fre...\n",
      "551    purchased low salt indeed low salt however man...\n",
      "554    chip greasy taste burntthere grease bottom bag...\n",
      "555    dont waste money kettle brand potato chip boug...\n",
      "556    defintely tasty madhouse munchies family favor...\n",
      "557    love sour food one cant bear strong sour taste...\n",
      "558    unless really really really like vinegar avoid...\n",
      "560    used eat spicy thai flavor time msg make body ...\n",
      "561    chip greatfor first bag however first bag two ...\n",
      "562    waiting ridiculous amount time case 15 5oz bag...\n",
      "566    terrible cannot believe received item every si...\n",
      "568    kettle branch potato chip new york cheddar goo...\n",
      "576    like order kettle spicy thai chip amazon hard ...\n",
      "582    admit oversalted chip addictive really think o...\n",
      "621    sent 3 week past fresh date stock chip noticea...\n",
      "623    problem order case 12 good half time best kett...\n",
      "Name: Text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Prétraitement des données\n",
    "\n",
    "data.drop(['Id', 'ProductId','UserId', 'ProfileName', 'HelpfulnessNumerator', 'HelpfulnessDenominator', 'Time',], axis=1, inplace=True)\n",
    "data = data.dropna()\n",
    "data['Text'] = data['Text'].apply(lambda x: re.sub('<.*?>', '', x))  # Suppression des balises HTML\n",
    "data['Text'] = data['Text'].apply(lambda x: re.sub(r'[^\\w\\s]', '', x))  # Suppression des caractères spéciaux\n",
    "data['Text'] = data['Text'].apply(lambda x: x.lower())  # Mise en minuscules\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "data['Text'] = data['Text'].apply(lambda x: ' '.join(word for word in x.split() if word not in stop_words))  # Suppression des stopwords\n",
    "data['Text'] = data['Text'].apply(lambda x: ' '.join(lemmatizer.lemmatize(word) for word in x.split()))  # Lemmatisation\n",
    "\n",
    "print (data['Text'])\n",
    "\n",
    "\n",
    "\n",
    "# Créer une liste de documents tokenisés à partir de la colonne 'Text'\n",
    "documents = [text.split() for text in data['Text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['perhaps', 'worst', 'chip', 'ever', 'gone', 'mouthfor', 'entire', 'life', 'sour', 'cream', 'onion', 'case', 'chive', 'chip', 'favorite', 'recently', 'kettle', 'brand', 'honey', 'dijon', 'mustard', 'took', 'slot', 'found', 'sour', 'cream', 'onion', 'try', 'themas', 'soon']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(documents[:1][0][:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Créer un dictionnaire\n",
    "dictionary = corpora.Dictionary(documents)\n",
    "\n",
    "\n",
    "# Créer un corpus\n",
    "corpus = [dictionary.doc2bow(doc) for doc in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 8), (11, 1), (12, 1), (13, 1), (14, 4), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 3)]\n"
     ]
    }
   ],
   "source": [
    "print(corpus[:1][0][:30])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Meilleurs hyperparamètres :\n",
      "Numéro de topics : 15\n",
      "Nombre de passes : 1500\n",
      "Meilleur score de cohérence : 0.5529187135664118\n",
      "[(0,\n",
      "  '0.011*\"overfried\" + 0.006*\"tired\" + 0.006*\"trial\" + 0.006*\"point\" + '\n",
      "  '0.006*\"selling\" + 0.006*\"suffer\" + 0.006*\"claim\" + 0.006*\"natural\" + '\n",
      "  '0.006*\"pingosit\" + 0.006*\"luck\"'),\n",
      " (1,\n",
      "  '0.012*\"favorite\" + 0.010*\"feel\" + 0.010*\"cut\" + 0.010*\"crinkle\" + '\n",
      "  '0.010*\"hefty\" + 0.008*\"lay\" + 0.008*\"look\" + 0.008*\"longer\" + 0.005*\"used\" '\n",
      "  '+ 0.004*\"taste\"'),\n",
      " (2,\n",
      "  '0.002*\"munchies\" + 0.002*\"tasty\" + 0.002*\"darkburntmore\" + '\n",
      "  '0.002*\"defintely\" + 0.002*\"family\" + 0.002*\"greasyoily\" + 0.002*\"light\" + '\n",
      "  '0.002*\"madhouse\" + 0.002*\"broken\" + 0.002*\"oh\"'),\n",
      " (3,\n",
      "  '0.013*\"bottom\" + 0.011*\"greasy\" + 0.007*\"fat\" + 0.007*\"burntthere\" + '\n",
      "  '0.007*\"need\" + 0.007*\"lot\" + 0.007*\"trans\" + 0.007*\"especially\" + '\n",
      "  '0.007*\"saturated\" + 0.006*\"le\"'),\n",
      " (4,\n",
      "  '0.010*\"fried\" + 0.008*\"new\" + 0.006*\"potato\" + 0.006*\"already\" + '\n",
      "  '0.006*\"burnt\" + 0.006*\"branch\" + 0.006*\"hit\" + 0.006*\"york\" + '\n",
      "  '0.006*\"cheese\" + 0.006*\"sort\"'),\n",
      " (5,\n",
      "  '0.016*\"vinegar\" + 0.011*\"sea\" + 0.009*\"thai\" + 0.009*\"really\" + '\n",
      "  '0.008*\"spicy\" + 0.008*\"salt\" + 0.006*\"husband\" + 0.006*\"potatoe\" + '\n",
      "  '0.006*\"paid\" + 0.006*\"locally\"'),\n",
      " (6,\n",
      "  '0.007*\"flavvorssalt\" + 0.007*\"cheeseny\" + 0.007*\"ordered\" + 0.007*\"pack\" + '\n",
      "  '0.007*\"peppertuscan\" + 0.007*\"return\" + 0.007*\"ground\" + 0.007*\"sizei\" + '\n",
      "  '0.007*\"unopened\" + 0.007*\"variety\"'),\n",
      " (7,\n",
      "  '0.007*\"box\" + 0.007*\"crunch\" + 0.007*\"oh\" + 0.007*\"munchies\" + '\n",
      "  '0.007*\"madhouse\" + 0.007*\"light\" + 0.007*\"family\" + 0.007*\"defintely\" + '\n",
      "  '0.007*\"darkburntmore\" + 0.007*\"tasty\"'),\n",
      " (8,\n",
      "  '0.012*\"nasty\" + 0.009*\"bag\" + 0.009*\"plain\" + 0.008*\"someone\" + '\n",
      "  '0.008*\"found\" + 0.007*\"numerous\" + 0.007*\"happen\" + 0.007*\"none\" + '\n",
      "  '0.007*\"soaked\" + 0.007*\"spilled\"'),\n",
      " (9,\n",
      "  '0.011*\"low\" + 0.009*\"many\" + 0.008*\"salt\" + 0.008*\"oil\" + 0.007*\"never\" + '\n",
      "  '0.006*\"purchased\" + 0.006*\"encountered\" + 0.006*\"unappetizing\" + '\n",
      "  '0.006*\"others\" + 0.006*\"dripping\"'),\n",
      " (10,\n",
      "  '0.010*\"yuck\" + 0.008*\"unedible\" + 0.008*\"brand\" + 0.007*\"give\" + '\n",
      "  '0.006*\"item\" + 0.006*\"good\" + 0.006*\"better\" + 0.006*\"stale\" + 0.005*\"big\" '\n",
      "  '+ 0.005*\"crunchy\"'),\n",
      " (11,\n",
      "  '0.011*\"best\" + 0.007*\"potato\" + 0.006*\"company\" + 0.006*\"case\" + '\n",
      "  '0.006*\"product\" + 0.005*\"good\" + 0.004*\"get\" + 0.004*\"try\" + 0.004*\"order\" '\n",
      "  '+ 0.004*\"weird\"'),\n",
      " (12,\n",
      "  '0.009*\"msg\" + 0.008*\"cream\" + 0.007*\"onion\" + 0.007*\"sour\" + 0.005*\"flavor\" '\n",
      "  '+ 0.005*\"rancid\" + 0.005*\"texture\" + 0.005*\"powdered\" + 0.005*\"powdery\" + '\n",
      "  '0.005*\"milk\"'),\n",
      " (13,\n",
      "  '0.013*\"sour\" + 0.012*\"strong\" + 0.011*\"case\" + 0.008*\"money\" + '\n",
      "  '0.008*\"waste\" + 0.008*\"ended\" + 0.008*\"garbage\" + 0.007*\"awful\" + '\n",
      "  '0.007*\"smell\" + 0.007*\"cant\"'),\n",
      " (14,\n",
      "  '0.011*\"amazon\" + 0.008*\"stock\" + 0.008*\"rat\" + 0.008*\"picture\" + '\n",
      "  '0.007*\"hole\" + 0.006*\"fresh\" + 0.006*\"box\" + 0.006*\"email\" + 0.006*\"mouse\" '\n",
      "  '+ 0.005*\"noticeably\"')]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import LdaMulticore, TfidfModel,LdaModel\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "# Création du modèle TF-IDF\n",
    "tfidf_model = TfidfModel(corpus)\n",
    "corpus_tfidf = tfidf_model[corpus]\n",
    "\n",
    "# Paramètres à tester\n",
    "num_topics_list = [5, 10, 15]  # Liste des nombres de topics à tester\n",
    "passes_list = [1000, 1500, 2000]  # Liste des nombres de passes à tester\n",
    "\n",
    "best_coherence_score = -1\n",
    "best_lda_model = None\n",
    "best_num_topics = 0\n",
    "best_passes = 0\n",
    "\n",
    "for num_topics in num_topics_list:\n",
    "    for passes in passes_list:\n",
    "        # Entraînement du modèle LDA\n",
    "        lda_model = LdaModel(corpus=corpus_tfidf,\n",
    "                             id2word=dictionary,\n",
    "                             num_topics=num_topics,\n",
    "                             passes=passes)\n",
    "        \n",
    "        # Calcul de la cohérence pour évaluer le modèle\n",
    "        coherence_model = CoherenceModel(model=lda_model, texts=documents, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_score = coherence_model.get_coherence()\n",
    "        \n",
    "        # Comparaison avec le meilleur score obtenu jusqu'à présent\n",
    "        if coherence_score > best_coherence_score:\n",
    "            best_coherence_score = coherence_score\n",
    "            best_lda_model = lda_model\n",
    "            best_num_topics = num_topics\n",
    "            best_passes = passes\n",
    "\n",
    "# Affichage des meilleurs hyperparamètres et du meilleur modèle\n",
    "print(\"Meilleurs hyperparamètres :\")\n",
    "print(\"Numéro de topics :\", best_num_topics)\n",
    "print(\"Nombre de passes :\", best_passes)\n",
    "print(\"Meilleur score de cohérence :\", best_coherence_score)\n",
    "\n",
    "# Affichage des topics du meilleur modèle\n",
    "pprint(best_lda_model.print_topics())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 5:\n",
      "yuck, give, flavor, cream, sour, could, onion, product, brand, powdery\n",
      "\n",
      "Topic 11:\n",
      "low, awful, never, many, opened, ever, box, salt, oil, literally\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Choisissez un document à analyser\n",
    "document_index = 0\n",
    "document = documents[document_index]\n",
    "\n",
    "# Convertissez le document en une représentation vectorielle\n",
    "vector = dictionary.doc2bow(document)\n",
    "\n",
    "# Obtenez la distribution de probabilité des topics pour le document\n",
    "topic_distribution = lda_model[vector]\n",
    "\n",
    "# Triez les topics par ordre décroissant de probabilité\n",
    "sorted_topics = sorted(topic_distribution, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Affichez les mots clés des topics les plus pertinents\n",
    "num_keywords = 10  # Nombre de mots clés à afficher par topic\n",
    "\n",
    "for topic in sorted_topics:\n",
    "    topic_id = topic[0]\n",
    "    topic_keywords = lda_model.show_topic(topic_id, num_keywords)\n",
    "    topic_keywords = [keyword[0] for keyword in topic_keywords]\n",
    "    \n",
    "    print(f\"Topic {topic_id + 1}:\")\n",
    "    print(\", \".join(topic_keywords))\n",
    "    print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitude :  0.69675\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Charger les données depuis un fichier CSV\n",
    "data = pd.read_csv('data.csv',nrows=20000)\n",
    "\n",
    "# Diviser les données en variables indépendantes (X) et dépendante (y)\n",
    "X = data['Text']\n",
    "y = data['Score']\n",
    "\n",
    "# Diviser les données en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Créer une représentation vectorielle des textes en utilisant TF-IDF\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)\n",
    "\n",
    "# Entraîner un modèle de classification (par exemple, SVM linéaire)\n",
    "model = LinearSVC()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Faire des prédictions sur les données de test\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Évaluer l'exactitude du modèle\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Exactitude : \", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have bought several of the Vitality canned dog food products and have found them all to be of good quality. The product looks more like a stew than a processed meat and it smells better. My Labrador is finicky and she appreciates this product better than  most. Product arrived labeled as Jumbo Salted Peanuts...the peanuts were actually small sized unsalted. Not sure if this was an error or if the vendor intended to represent the product as \"Jumbo\". This is a confection that has been around a few centuries.  It is a light, pillowy citrus gelatin with nuts - in this case Filberts. And it is cut into tiny squares and then liberally coated with powdered sugar.  And it is a tiny mouthful of heaven.  Not too chewy, and very flavorful.  I highly recommend this yummy treat.  If you are familiar with the story of C.S. Lewis' \"The Lion, The Witch, and The Wardrobe\" - this is the treat that seduces Edmund into selling out his Brother and Sisters to the Witch. If you are looking for the secret ingredient in Robitussin I believe I have found it.  I got this in addition to the Root Beer Extract I ordered (which was good) and made some cherry soda.  The flavor is very medicinal. Great taffy at a great price.  There was a wide assortment of yummy taffy.  Delivery was very quick.  If your a taffy lover, this is a deal. I got a wild hair for taffy and ordered this five pound bag. The taffy was all very enjoyable with many flavors: watermelon, root beer, melon, peppermint, grape, etc. My only complaint is there was a bit too much red/black licorice-flavored pieces (just not my particular favorites). Between me, my kids, and my husband, this lasted only two weeks! I would recommend this brand of taffy -- it was a delightful treat. This saltwater taffy had great flavors and was very soft and chewy.  Each candy was individually wrapped well.  None of the candies were stuck together, which did happen in the expensive version, Fralinger's.  Would highly recommend this candy!  I served it at a beach-themed party and everyone loved it! This taffy is so good.  It is very soft and chewy.  The flavors are amazing.  I would definitely recommend you buying it.  Very satisfying!! Right now I'm mostly just sprouting this so my cats can eat the grass. They love it. I rotate it around with Wheatgrass and Rye too This is a very healthy dog food. Good for their digestion. Also good for small puppies. My dog eats her required amount at every feeding.\n",
      "Vitality canned dog food products are of good quality. The product looks more like a stew than a processed meat and it smells better. My Labrador is finicky and she appreciates the product better than other dogs. This is a healthy dog food. Filberts popcorn is a snack that has been around for centuries. I served it at a beach-themed party and everyone loved it. If you are looking for the secret ingredient in Robitussin, try this product.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "summarizer = pipeline(\"summarization\", model=\"knkarthick/MEETING_SUMMARY\")\n",
    "\n",
    "   \n",
    "# Supposons que vous ayez un DataFrame appelé 'data' avec une colonne 'texte'\n",
    "texte_complet = \" \".join(data['Text'][:10].tolist())\n",
    "print(texte_complet)\n",
    "\n",
    "\n",
    "print(summarizer(texte_complet, min_length=50, max_length=200)[0]['summary_text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.2117144614458084, 'start': 59, 'end': 84, 'answer': 'gives freedom to the user'}\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForQuestionAnswering, AutoTokenizer, pipeline\n",
    "\n",
    "model_name = \"deepset/roberta-base-squad2\"\n",
    "\n",
    "# a) Get predictions\n",
    "nlp = pipeline('question-answering', model=model_name, tokenizer=model_name)\n",
    "QA_input = {\n",
    "    'question': 'Why is model conversion important?',\n",
    "    'context': 'The option to convert models between FARM and transformers gives freedom to the user and let people easily switch between frameworks.'\n",
    "}\n",
    "res = nlp(QA_input)\n",
    "\n",
    "# b) Load model & tokenizer\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import PegasusForConditionalGeneration, PegasusTokenizer\n",
    "model_name = 'tuner007/pegasus_paraphrase'\n",
    "torch_device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "tokenizer = PegasusTokenizer.from_pretrained(model_name)\n",
    "model = PegasusForConditionalGeneration.from_pretrained(model_name).to(torch_device)\n",
    "\n",
    "def get_response(input_text,num_return_sequences,num_beams):\n",
    "  batch = tokenizer([input_text],truncation=True,padding='longest',max_length=60, return_tensors=\"pt\").to(torch_device)\n",
    "  translated = model.generate(**batch,max_length=60,num_beams=num_beams, num_return_sequences=num_return_sequences, temperature=1.5)\n",
    "  tgt_text = tokenizer.batch_decode(translated, skip_special_tokens=True)\n",
    "  return tgt_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The user has freedom.',\n",
       " 'The user has the freedom to use.',\n",
       " 'The user is given freedom.',\n",
       " 'It gives the user freedom.',\n",
       " 'The user has the freedom to use it.']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_beams = 10\n",
    "num_return_sequences = 5\n",
    "context = \"gives freedom to the user\"\n",
    "get_response(context,num_return_sequences,num_beams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Versatile', 'Well-packaged', 'High-quality', 'User-friendly', 'Reliable']\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "classifier = pipeline(\"zero-shot-classification\",\n",
    "                      model=\"facebook/bart-large-mnli\")\n",
    "\n",
    "\n",
    "summary_words = [\n",
    "    \"Reliable\",\n",
    "    \"Efficient\",\n",
    "    \"High-quality\",\n",
    "    \"User-friendly\",\n",
    "    \"Innovative\",\n",
    "    \"Convenient\",\n",
    "    \"Fast\",\n",
    "    \"Secure\",\n",
    "    \"Disappointing\",\n",
    "]\n",
    "\n",
    "result = classifier(texte_complet, candidate_labels)\n",
    "sorted_labels = sorted(result['labels'], key=lambda x: result['scores'][result['labels'].index(x)], reverse=True)\n",
    "print(sorted_labels[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gives freedom to the user\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForQuestionAnswering, AutoTokenizer, pipeline\n",
    "\n",
    "model_name = \"deepset/roberta-base-squad2\"\n",
    "\n",
    "# a) Get predictions\n",
    "nlp = pipeline('question-answering', model=model_name, tokenizer=model_name)\n",
    "QA_input = {\n",
    "    'question': 'Why is model conversion important?',\n",
    "    'context': 'The option to convert models between FARM and transformers gives freedom to the user and let people easily switch between frameworks.'\n",
    "}\n",
    "res = nlp(QA_input)\n",
    "\n",
    "print(res['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The user has freedom.']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import PegasusForConditionalGeneration, PegasusTokenizer\n",
    "model_name = 'tuner007/pegasus_paraphrase'\n",
    "torch_device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "tokenizer = PegasusTokenizer.from_pretrained(model_name)\n",
    "model = PegasusForConditionalGeneration.from_pretrained(model_name).to(torch_device)\n",
    "\n",
    "def get_response(input_text,num_return_sequences,num_beams):\n",
    "  batch = tokenizer([input_text],truncation=True,padding='longest',max_length=60, return_tensors=\"pt\").to(torch_device)\n",
    "  translated = model.generate(**batch,max_length=60,num_beams=num_beams, num_return_sequences=num_return_sequences, temperature=1.5)\n",
    "  tgt_text = tokenizer.batch_decode(translated, skip_special_tokens=True)\n",
    "  return tgt_text\n",
    "\n",
    "num_beams = 10\n",
    "num_return_sequences = 1\n",
    "context = res['answer']\n",
    "get_response(context,num_return_sequences,num_beams)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
