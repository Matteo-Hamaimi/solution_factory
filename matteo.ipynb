{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Id   ProductId          UserId               ProfileName  \\\n",
      "508  509  B000G6RYNE  A3I5AT1101AS3A           Nikolette Tripp   \n",
      "509  510  B000G6RYNE  A22LENLDTGQIU7                R. Yamaoka   \n",
      "516  517  B000G6RYNE  A38KP1POQ191WT  Judy Schinske \"Veronica\"   \n",
      "528  529  B000G6RYNE  A1BXG0K7UD9CTD         MicTrik \"mictrik\"   \n",
      "537  538  B000G6RYNE  A18VDAH788BOAC                      Geeb   \n",
      "\n",
      "     HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
      "508                     1                       2      1  1233360000   \n",
      "509                     4                       7      1  1252713600   \n",
      "516                     0                       1      1  1279065600   \n",
      "528                    20                      27      1  1254009600   \n",
      "537                     1                       3      1  1331856000   \n",
      "\n",
      "                                            Summary  \\\n",
      "508                     Maybe the worst chips ever.   \n",
      "509                   Surprise 1  It's different...   \n",
      "516       I have had better \"Jalapeno Kettle Chips\"   \n",
      "528  They changed the Chips now they taste horrible   \n",
      "537                                  Gone down hill   \n",
      "\n",
      "                                                  Text  \n",
      "508  These are perhaps the worst chips that have ev...  \n",
      "509  Kettle chips now look, feel and taste like Lay...  \n",
      "516  These were nasty, they were so greasy and too ...  \n",
      "528  I once loved these chips and they were the onl...  \n",
      "537  When originally produced in England  these we'...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.metrics import accuracy_score\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from pprint import pprint\n",
    "import gensim.corpora as corpora\n",
    "\n",
    "\n",
    "\n",
    "# Charger le dataset\n",
    "df = pd.read_csv('data.csv',nrows=10000)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Filtrer les données pour le produit spécifique et les scores 1 et 5\n",
    "data = df.loc[(df['ProductId'] == 'B000G6RYNE') & (df['Score'] == 1)]\n",
    "\n",
    "print(data.head())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jh/lt1l6hb94_b8vqvq3m3ld1lm0000gn/T/ipykernel_1009/2821783067.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data.drop(['Id', 'ProductId','UserId', 'ProfileName', 'HelpfulnessNumerator', 'HelpfulnessDenominator', 'Time',], axis=1, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "508    perhaps worst chip ever gone mouthfor entire l...\n",
      "509    kettle chip look feel taste like lay chip used...\n",
      "516    nasty greasy rich blood plus lacked major flav...\n",
      "528    loved chip chip would buy discovered england b...\n",
      "537    originally produced england best chip ever tas...\n",
      "538    opening numerous bag found none chip flavoring...\n",
      "541    ive bought local supermarket enjoyed although ...\n",
      "543    kettle brand chip used goodoily crunchy flavor...\n",
      "544    absolutely forget confirmed reviewer chip tota...\n",
      "545    chip nasty thought someone spilled drink bag c...\n",
      "547    bought brand trial since tired pingosit claim ...\n",
      "550    ordered kettle chip following flavvorssalt fre...\n",
      "551    purchased low salt indeed low salt however man...\n",
      "554    chip greasy taste burntthere grease bottom bag...\n",
      "555    dont waste money kettle brand potato chip boug...\n",
      "556    defintely tasty madhouse munchies family favor...\n",
      "557    love sour food one cant bear strong sour taste...\n",
      "558    unless really really really like vinegar avoid...\n",
      "560    used eat spicy thai flavor time msg make body ...\n",
      "561    chip greatfor first bag however first bag two ...\n",
      "562    waiting ridiculous amount time case 15 5oz bag...\n",
      "566    terrible cannot believe received item every si...\n",
      "568    kettle branch potato chip new york cheddar goo...\n",
      "576    like order kettle spicy thai chip amazon hard ...\n",
      "582    admit oversalted chip addictive really think o...\n",
      "621    sent 3 week past fresh date stock chip noticea...\n",
      "623    problem order case 12 good half time best kett...\n",
      "Name: Text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Prétraitement des données\n",
    "\n",
    "data.drop(['Id', 'ProductId','UserId', 'ProfileName', 'HelpfulnessNumerator', 'HelpfulnessDenominator', 'Time',], axis=1, inplace=True)\n",
    "data = data.dropna()\n",
    "data['Text'] = data['Text'].apply(lambda x: re.sub('<.*?>', '', x))  # Suppression des balises HTML\n",
    "data['Text'] = data['Text'].apply(lambda x: re.sub(r'[^\\w\\s]', '', x))  # Suppression des caractères spéciaux\n",
    "data['Text'] = data['Text'].apply(lambda x: x.lower())  # Mise en minuscules\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "data['Text'] = data['Text'].apply(lambda x: ' '.join(word for word in x.split() if word not in stop_words))  # Suppression des stopwords\n",
    "data['Text'] = data['Text'].apply(lambda x: ' '.join(lemmatizer.lemmatize(word) for word in x.split()))  # Lemmatisation\n",
    "\n",
    "print (data['Text'])\n",
    "\n",
    "\n",
    "\n",
    "# Créer une liste de documents tokenisés à partir de la colonne 'Text'\n",
    "documents = [text.split() for text in data['Text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['taffy', 'good', 'soft', 'chewy', 'flavor', 'amazing', 'would', 'definitely', 'recommend', 'buying', 'satisfying']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(documents[:1][0][:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Créer un dictionnaire\n",
    "dictionary = corpora.Dictionary(documents)\n",
    "\n",
    "\n",
    "# Créer un corpus\n",
    "corpus = [dictionary.doc2bow(doc) for doc in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1)]\n"
     ]
    }
   ],
   "source": [
    "print(corpus[:1][0][:30])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleurs hyperparamètres :\n",
      "Numéro de topics : 10\n",
      "Nombre de passes : 1000\n",
      "Meilleur score de cohérence : 0.8229463924225117\n",
      "[(0,\n",
      "  '0.026*\"soft\" + 0.026*\"chewy\" + 0.026*\"flavor\" + 0.026*\"would\" + '\n",
      "  '0.026*\"recommend\" + 0.026*\"fralingers\" + 0.026*\"individually\" + '\n",
      "  '0.026*\"highly\" + 0.026*\"none\" + 0.026*\"beachthemed\"'),\n",
      " (1,\n",
      "  '0.061*\"candy\" + 0.040*\"price\" + 0.040*\"wide\" + 0.040*\"delivery\" + '\n",
      "  '0.040*\"lover\" + 0.040*\"deal\" + 0.040*\"quick\" + 0.040*\"yummy\" + '\n",
      "  '0.040*\"assortment\" + 0.038*\"great\"'),\n",
      " (2,\n",
      "  '0.026*\"soft\" + 0.026*\"chewy\" + 0.026*\"flavor\" + 0.026*\"would\" + '\n",
      "  '0.026*\"recommend\" + 0.026*\"fralingers\" + 0.026*\"individually\" + '\n",
      "  '0.026*\"highly\" + 0.026*\"none\" + 0.026*\"beachthemed\"'),\n",
      " (3,\n",
      "  '0.026*\"soft\" + 0.026*\"chewy\" + 0.026*\"flavor\" + 0.026*\"would\" + '\n",
      "  '0.026*\"recommend\" + 0.026*\"fralingers\" + 0.026*\"individually\" + '\n",
      "  '0.026*\"highly\" + 0.026*\"none\" + 0.026*\"beachthemed\"'),\n",
      " (4,\n",
      "  '0.078*\"good\" + 0.078*\"satisfying\" + 0.078*\"amazing\" + 0.078*\"buying\" + '\n",
      "  '0.078*\"definitely\" + 0.038*\"soft\" + 0.038*\"would\" + 0.038*\"chewy\" + '\n",
      "  '0.038*\"recommend\" + 0.038*\"flavor\"'),\n",
      " (5,\n",
      "  '0.026*\"soft\" + 0.026*\"chewy\" + 0.026*\"flavor\" + 0.026*\"would\" + '\n",
      "  '0.026*\"recommend\" + 0.026*\"fralingers\" + 0.026*\"individually\" + '\n",
      "  '0.026*\"highly\" + 0.026*\"none\" + 0.026*\"beachthemed\"'),\n",
      " (6,\n",
      "  '0.026*\"soft\" + 0.026*\"chewy\" + 0.026*\"flavor\" + 0.026*\"would\" + '\n",
      "  '0.026*\"recommend\" + 0.026*\"fralingers\" + 0.026*\"individually\" + '\n",
      "  '0.026*\"highly\" + 0.026*\"none\" + 0.026*\"beachthemed\"'),\n",
      " (7,\n",
      "  '0.026*\"soft\" + 0.026*\"chewy\" + 0.026*\"flavor\" + 0.026*\"would\" + '\n",
      "  '0.026*\"recommend\" + 0.026*\"fralingers\" + 0.026*\"individually\" + '\n",
      "  '0.026*\"highly\" + 0.026*\"none\" + 0.026*\"beachthemed\"'),\n",
      " (8,\n",
      "  '0.026*\"soft\" + 0.026*\"chewy\" + 0.026*\"flavor\" + 0.026*\"would\" + '\n",
      "  '0.026*\"recommend\" + 0.026*\"fralingers\" + 0.026*\"individually\" + '\n",
      "  '0.026*\"highly\" + 0.026*\"none\" + 0.026*\"beachthemed\"'),\n",
      " (9,\n",
      "  '0.026*\"soft\" + 0.026*\"chewy\" + 0.026*\"flavor\" + 0.026*\"would\" + '\n",
      "  '0.026*\"recommend\" + 0.026*\"fralingers\" + 0.026*\"individually\" + '\n",
      "  '0.026*\"highly\" + 0.026*\"none\" + 0.026*\"beachthemed\"')]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import LdaMulticore, TfidfModel,LdaModel\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "# Création du modèle TF-IDF\n",
    "tfidf_model = TfidfModel(corpus)\n",
    "corpus_tfidf = tfidf_model[corpus]\n",
    "\n",
    "# Paramètres à tester\n",
    "num_topics_list = [5, 10, 15]  # Liste des nombres de topics à tester\n",
    "passes_list = [1000, 1500, 2000]  # Liste des nombres de passes à tester\n",
    "\n",
    "best_coherence_score = -1\n",
    "best_lda_model = None\n",
    "best_num_topics = 0\n",
    "best_passes = 0\n",
    "\n",
    "for num_topics in num_topics_list:\n",
    "    for passes in passes_list:\n",
    "        # Entraînement du modèle LDA\n",
    "        lda_model = LdaModel(corpus=corpus_tfidf,\n",
    "                             id2word=dictionary,\n",
    "                             num_topics=num_topics,\n",
    "                             passes=passes)\n",
    "        \n",
    "        # Calcul de la cohérence pour évaluer le modèle\n",
    "        coherence_model = CoherenceModel(model=lda_model, texts=documents, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_score = coherence_model.get_coherence()\n",
    "        \n",
    "        # Comparaison avec le meilleur score obtenu jusqu'à présent\n",
    "        if coherence_score > best_coherence_score:\n",
    "            best_coherence_score = coherence_score\n",
    "            best_lda_model = lda_model\n",
    "            best_num_topics = num_topics\n",
    "            best_passes = passes\n",
    "\n",
    "# Affichage des meilleurs hyperparamètres et du meilleur modèle\n",
    "print(\"Meilleurs hyperparamètres :\")\n",
    "print(\"Numéro de topics :\", best_num_topics)\n",
    "print(\"Nombre de passes :\", best_passes)\n",
    "print(\"Meilleur score de cohérence :\", best_coherence_score)\n",
    "\n",
    "# Affichage des topics du meilleur modèle\n",
    "pprint(best_lda_model.print_topics())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 11:\n",
      "good, satisfying, amazing, buying, definitely, soft, would, chewy, recommend, flavor\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Choisissez un document à analyser\n",
    "document_index = 0\n",
    "document = documents[document_index]\n",
    "\n",
    "# Convertissez le document en une représentation vectorielle\n",
    "vector = dictionary.doc2bow(document)\n",
    "\n",
    "# Obtenez la distribution de probabilité des topics pour le document\n",
    "topic_distribution = lda_model[vector]\n",
    "\n",
    "# Triez les topics par ordre décroissant de probabilité\n",
    "sorted_topics = sorted(topic_distribution, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Affichez les mots clés des topics les plus pertinents\n",
    "num_keywords = 10  # Nombre de mots clés à afficher par topic\n",
    "\n",
    "for topic in sorted_topics:\n",
    "    topic_id = topic[0]\n",
    "    topic_keywords = lda_model.show_topic(topic_id, num_keywords)\n",
    "    topic_keywords = [keyword[0] for keyword in topic_keywords]\n",
    "    \n",
    "    print(f\"Topic {topic_id + 1}:\")\n",
    "    print(\", \".join(topic_keywords))\n",
    "    print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitude :  0.69675\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Charger les données depuis un fichier CSV\n",
    "data = pd.read_csv('data.csv',nrows=20000)\n",
    "\n",
    "# Diviser les données en variables indépendantes (X) et dépendante (y)\n",
    "X = data['Text']\n",
    "y = data['Score']\n",
    "\n",
    "# Diviser les données en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Créer une représentation vectorielle des textes en utilisant TF-IDF\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)\n",
    "\n",
    "# Entraîner un modèle de classification (par exemple, SVM linéaire)\n",
    "model = LinearSVC()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Faire des prédictions sur les données de test\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Évaluer l'exactitude du modèle\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Exactitude : \", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "perhaps worst chip ever gone mouthfor entire life sour cream onion case chive chip favorite recently kettle brand honey dijon mustard took slot found sour cream onion try themas soon opened bag chip smelled powdered milk indeed chip coated powdered sour cream awful taste like rancid milk sour like sour cream rancid powdery texture also extremely unappealing basically hated chip would recommend chip anyone unless particular affinity powdery chalky texture chip rancid onion flavor hard time believing person existsi plan contacting kettle sharing thought hopefully theyll reassess seasoning otherwise wonderful kettle style chip kettle chip look feel taste like lay chip used favorite crinkle cut hefty longer favorite nasty greasy rich blood plus lacked major flavor spicy jalapeno flavor dissapointed chip always hearing great thing chip telling yuck yuck yuck give pain chip day maybe better kettle chip brand staying clear chip wish could give zero star could loved chip chip would buy discovered england back 2000 quickly became fan year ago picked bag sale local supermarket finding odd sale much took advantage opening bag found chip even close kettle chip used uniform whitish yellow color flavor way lovely extra crisp brown chip gone completely disappointed emailed kettle following happened bought bag chip day different taste taste cheaper dont know else put also noticed chip seemed le cooked see browner colored chip flavor hoping nothing changed ingredient process used produce product get weird batch buying kettle chip 10 year wondering receive reply thanks letting u know experience kettle brand chip sound like may received bag slipped inspection apologizeour potato vary seasonally could account variation colorbut chip still taste greatthanks providing u best code bag really help passing comment staffwe sending coupon replace purchase kettle brand flavor nut butter believing great experience next purchase case buy product suggest avoiding best date still rare instance another bag case slipped inspection timethanks letting u know expect coupon arrive within 3 week please let know help well next bag good since time picked 3 bag chip like bad bag pretty sure changed product reduce cost research found kettle bought private equity company cookie cutter management process probably employed kettle acquire company high quality brand recognition sell product mass merchant lower qualitycost product increase margin finally sell company customer base start realize brand longer quality brand increased profit make company valuable paper make nice profit investor customer employee lose course unsuspecting buyer exploited brand stay away kettle chip longer originally produced england best chip ever tasted unfortunately since bought u conglomerate taste plain nasty hard rather crispy much thinner used lacking flavour real shame opening numerous bag found none chip flavoring completely plain gross even happen ive bought local supermarket enjoyed although salty leave tongue roof mouth burning keep eating many occasionally get really stale item amazoncom one unedible beware quality food item website special close due date case expired stale unedible kettle brand chip used goodoily crunchy flavorful suspect company bought recipe changed worse theyre better big name brand chip try good health kettle style olive oil chip instead good kettle brand rip kettle brand chip absolutely forget confirmed reviewer chip total garbage like chewing styrofoam packaging peanut positively awful hyperbole exaggeration ill never buy anything kettle brand ever reportedly great premium brand literally mass market chip ive ever tried taste better stale rancid tasting virtually salty taste whatsoever completely awful chip nasty thought someone spilled drink bag chip soaked grease nasty\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'summary_text': 'Kettle chips are not as good as they used to be. The quality of the chips has deteriorated since they were bought by the company that owns them. The company is sending a coupon for a new chip to the customer. '}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "summarizer = pipeline(\"summarization\", model=\"knkarthick/MEETING_SUMMARY\")\n",
    "\n",
    "   \n",
    "# Supposons que vous ayez un DataFrame appelé 'data' avec une colonne 'texte'\n",
    "texte_complet = \" \".join(data['Text'][:10].tolist())\n",
    "print(texte_complet)\n",
    "\n",
    "summarizer(texte_complet, min_length=50, max_length=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.2117144614458084, 'start': 59, 'end': 84, 'answer': 'gives freedom to the user'}\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForQuestionAnswering, AutoTokenizer, pipeline\n",
    "\n",
    "model_name = \"deepset/roberta-base-squad2\"\n",
    "\n",
    "# a) Get predictions\n",
    "nlp = pipeline('question-answering', model=model_name, tokenizer=model_name)\n",
    "QA_input = {\n",
    "    'question': 'Why is model conversion important?',\n",
    "    'context': 'The option to convert models between FARM and transformers gives freedom to the user and let people easily switch between frameworks.'\n",
    "}\n",
    "res = nlp(QA_input)\n",
    "\n",
    "# b) Load model & tokenizer\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1.91M/1.91M [00:00<00:00, 4.41MB/s]\n",
      "Downloading: 100%|██████████| 65.0/65.0 [00:00<00:00, 20.3kB/s]\n",
      "Downloading: 100%|██████████| 86.0/86.0 [00:00<00:00, 25.0kB/s]\n",
      "Downloading: 100%|██████████| 1.14k/1.14k [00:00<00:00, 404kB/s]\n",
      "Downloading: 100%|██████████| 2.28G/2.28G [02:11<00:00, 17.3MB/s] \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import PegasusForConditionalGeneration, PegasusTokenizer\n",
    "model_name = 'tuner007/pegasus_paraphrase'\n",
    "torch_device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "tokenizer = PegasusTokenizer.from_pretrained(model_name)\n",
    "model = PegasusForConditionalGeneration.from_pretrained(model_name).to(torch_device)\n",
    "\n",
    "def get_response(input_text,num_return_sequences,num_beams):\n",
    "  batch = tokenizer([input_text],truncation=True,padding='longest',max_length=60, return_tensors=\"pt\").to(torch_device)\n",
    "  translated = model.generate(**batch,max_length=60,num_beams=num_beams, num_return_sequences=num_return_sequences, temperature=1.5)\n",
    "  tgt_text = tokenizer.batch_decode(translated, skip_special_tokens=True)\n",
    "  return tgt_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The user has freedom.',\n",
       " 'The user has the freedom to use.',\n",
       " 'The user is given freedom.',\n",
       " 'It gives the user freedom.',\n",
       " 'The user has the freedom to use it.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_beams = 10\n",
    "num_return_sequences = 5\n",
    "context = \"gives freedom to the user\"\n",
    "get_response(context,num_return_sequences,num_beams)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
